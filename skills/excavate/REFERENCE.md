# excavate — reference

extended examples, genre-specific patterns, and detailed scoring criteria.

---

## genre-specific patterns

### strategic decisions
uncover resource assumptions, competitive assumptions, timeline assumptions, reversibility assumptions.

### forecasts
uncover scaling assumptions, incentive assumptions, regime-shift assumptions.

### principles / values
uncover moral weightings, tradeoff priorities, implicit boundary conditions.

### product decisions
uncover user-behavior assumptions, trust assumptions, execution constraints.

---

## quality checklist (detailed)

**structural clarity**
- [ ] layers are clean, no duplicated logic
- [ ] tags correctly classify assumption types

**crux identification**
- [ ] 3–7 assumptions marked as genuine load-bearing points
- [ ] cruxes differ meaningfully in type or leverage

**diagnostic sharpness**
- [ ] surfaces where actual disagreement likely lives
- [ ] distinguishes empirical uncertainty from value conflict

**actionable probes**
- [ ] each probe targets a crux
- [ ] probes are measurable, investigable, or framable

---

## worked examples

### example 1: excavate "ai alignment should be a major global priority"

**layer 1**
- [empirical] [CRUX] ai will reach capability levels where misalignment is dangerous
- [empirical] misalignment is plausible even with good-faith designers
- [normative] preventing large-scale harm is morally prioritized
- [structural] [HIGH-UNCERTAINTY] coordination across major actors is feasible
- [definitional] alignment can be specified non-vacuously

**layer 2 (samples)**
- under "misalignment plausible":
  - [empirical] oversight is imperfect
  - [empirical] specification gaming emerges under optimization
- under "coordination feasible":
  - [structural] incentives can be altered
  - [structural] enforcement mechanisms can exist

**cruxes**
- ai reaches dangerous capability (empirical)
- deployment incentives outpace safety (structural)
- operational alignment definitions exist (definitional)

**probes**
- what empirical thresholds constitute "dangerous capability"?
- what historical cases resemble high-stakes coordination under competition?
- can alignment metrics be hardened against gaming?

---

### example 2: excavate "we should launch a premium tier this year"

**layer 1**
- [empirical] [CRUX] enough users have willingness-to-pay
- [empirical] differentiated value can be delivered
- [structural] [CRUX] premium will not damage the base through cannibalization
- [structural] roadmap capacity exists
- [psychological] users won't interpret premium as nickel-and-diming

**layer 2 (samples)**
- under "willingness-to-pay":
  - [empirical] clear segments with unmet needs exist
  - [empirical] budget authority sits with target users
- under "not damaging the base":
  - [structural] pricing avoids degrading the existing tier
  - [psychological] early adopters won't feel penalized

**cruxes**
- real willingness-to-pay exists (empirical)
- differentiation is materially deliverable (empirical/structural)
- trust won't erode under tiering (structural/psychological)

**probes**
- run a reversible pilot with a targeted user cohort
- measure sentiment shifts relative to existing users
- test feature-bundle differentiation assumptions explicitly
